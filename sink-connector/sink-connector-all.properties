 
# -----------------------------------
# Connector identity & class
# -----------------------------------
name=jdbc-avro-sink-all
connector.class=io.confluent.connect.jdbc.JdbcSinkConnector
tasks.max=3
 
# -----------------------------------
# Topics to consume
# -----------------------------------
topics=OEORDHAVROQAOC,OEORDLAVROQAOC,WMOPCKHAVROQAOC,SHIP_CODEAVROQAOC,DL_RTEAVROQAOC
 
# -----------------------------------
# Converters (key & value are Avro)
# -----------------------------------
key.converter=io.confluent.connect.avro.AvroConverter
key.converter.schema.registry.url=http://kregistry.stream-qa.router-default.apps.pamnoscqas100.panetcorp.com/apis/ccompat/v7
key.converter.enhanced.avro.schema.support=true
key.converter.connect.meta.data=false
 
value.converter=io.confluent.connect.avro.AvroConverter
value.converter.schema.registry.url=http://kregistry.stream-qa.router-default.apps.pamnoscqas100.panetcorp.com/apis/ccompat/v7
value.converter.enhanced.avro.schema.support=true
value.converter.connect.meta.data=false
 
# -----------------------------------
# JDBC connection (PostgreSQL)
# -----------------------------------
connection.url=jdbc:postgresql://localhost:5432/grafana
connection.user=postgres
connection.password=postgres
 
# -----------------------------------
# Table routing & management
# -----------------------------------
# Single table for all topics (raw landing)
table.name.format=kafka_raw_ingest
auto.create=true
auto.evolve=true
 
# -----------------------------------
# Insert behavior (append-only)
# -----------------------------------
insert.mode=insert
pk.mode=none
 
# -----------------------------------
# Performance & resiliency
# -----------------------------------
batch.size=800
max.retries=10
retry.backoff.ms=3000
 
# -----------------------------------
# Error handling
# -----------------------------------
errors.tolerance=all
errors.log.enable=true
errors.log.include.messages=true
errors.deadletterqueue.topic.name=dlq-kafka-raw-ingest
errors.deadletterqueue.topic.replication.factor=3
errors.deadletterqueue.context.headers.enable=true
 
# -----------------------------------
# SMT: add Kafka metadata into the record value
# -----------------------------------
transforms=AddMeta
transforms.AddMeta.type=org.apache.kafka.connect.transforms.InsertField$Value
transforms.AddMeta.topic.field=topic
transforms.AddMeta.partition.field=partition
transforms.AddMeta.offset.field=offset
transforms.AddMeta.timestamp.field=received_at
transforms.AddMeta.timestamp.format=yyyy-MM-dd'T'HH:mm:ss.SSSZ
transforms.AddMeta.static.field=ingest_source
transforms.AddMeta.static.value=kafka
