input {
  kafka {
    bootstrap_servers => "kafka:9092"
    topics => ["executive_metrics"]
    codec => "json"
    group_id => "logstash-timescale-consumer"
    consumer_threads => 1
    decorate_events => true
  }
}

filter {
  # Parse the timestamp if it's a string
  date {
    match => ["timestamp", "ISO8601", "UNIX", "UNIX_MS"]
    target => "@timestamp"
  }
  
  # Ensure fields exist with defaults
  mutate {
    add_field => {
      "db_timestamp" => "%{@timestamp}"
    }
  }
}

output {
  jdbc {
    driver_class => "org.postgresql.Driver"
    connection_string => "jdbc:postgresql://timescaledb:5432/analytics"
    username => "admin"
    password => "admin123"
    statement => "INSERT INTO metrics (time, metric, value, region) VALUES (CAST(? AS TIMESTAMP), ?, CAST(? AS DOUBLE PRECISION), ?) ON CONFLICT DO NOTHING"
    parameters => {
      "db_timestamp" => "@timestamp"
      "metric" => "[metric]"
      "value" => "[value]"
      "region" => "[region]"
    }
  }
  
  # Optional: Log to stdout for debugging
  stdout {
    codec => rubydebug
  }
}